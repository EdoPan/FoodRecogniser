{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noIWJhJ9jflE"
      },
      "source": [
        "**Instantiating the MobileNetV2 model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO-oN0Hjnn42"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  model.add(resize_and_rescale)\n",
        "  model.add(data_augmentation)\n",
        "  model.add(base_model)\n",
        "  model.add(layers.GlobalAveragePooling2D())\n",
        "  model.add(layers.Dense(hp.Choice('filters_1', values=[512, 1024]), activation='relu'))\n",
        "  model.add(layers.Dense(hp.Choice('filters_2', values=[512, 1024]), activation='relu'))\n",
        "  # Tune whether to use dropout.\n",
        "  if hp.Boolean(\"dropout\"):\n",
        "    model.add(layers.Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "  model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "  model.build((None,) + input_shape)\n",
        "  learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
        "  # Complitation of the model\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate',\n",
        "                                                                          values=[1e-2, 1e-3, 1e-4]),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iq1zD4Ju-1X"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "import os\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "import io\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "import pydot\n",
        "import graphviz\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "import keras\n",
        "from matplotlib import pyplot\n",
        "import keras_tuner\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# Parametri di addestramento\n",
        "batch_size = 32\n",
        "input_shape = (224, 224, 3)\n",
        "image_size = (224, 224)\n",
        "num_classes = 101\n",
        "epochs = 15\n",
        "\n",
        "savingData_dir_name = \"./IntelligentSystems/stats\"\n",
        "if not os.path.exists(savingData_dir_name):\n",
        "  os.makedirs(savingData_dir_name)\n",
        "\n",
        "# Instantiating the MobileNetV2 pre-trained model\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "# Congelamento dei pesi del modello base\n",
        "base_model.trainable = False\n",
        "\n",
        "# Crea un oggetto StringIO per salvare il summary del modello come stringa\n",
        "summary_string = io.StringIO()\n",
        "\n",
        "# Salva il summary del modello come stringa\n",
        "base_model.summary(print_fn=lambda x: summary_string.write(x + '\\n'))\n",
        "\n",
        "# Scrivi la stringa su un file\n",
        "with open('./IntelligentSystems/stats/model_summary.txt', 'w') as f:\n",
        "  f.write(summary_string.getvalue())\n",
        "\n",
        "# Salva una rappresentazione grafica del modello come immagine\n",
        "tf.keras.utils.plot_model(base_model, to_file='./IntelligentSystems/stats/pre_trained_model_plot.png', show_shapes=True, show_layer_names=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN7NuQWepJ45"
      },
      "source": [
        "**Loading the datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ANFmfA0pHjk"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content\")\n",
        "# Percorso delle cartelle di train, validation e test\n",
        "train_dir = \"./dataset/food-101/train\"\n",
        "val_dir = \"./dataset/food-101/validation\"\n",
        "test_dir = \"./dataset/food-101/test\"\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator()\n",
        "val_datagen = ImageDataGenerator()\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "\t# Carica i dati di training\n",
        "trainGenerator = train_datagen.flow_from_directory(\n",
        "\ttrain_dir,\n",
        "\ttarget_size=image_size,\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='categorical',\n",
        "\tshuffle=True  # Imposta shuffle a True\n",
        ")\n",
        "\n",
        "\t# Carica i dati di validation\n",
        "valGenerator = val_datagen.flow_from_directory(\n",
        "\tval_dir,\n",
        "\ttarget_size=image_size,\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='categorical',\n",
        "\tshuffle=True  # Imposta shuffle a True\n",
        ")\n",
        "\n",
        "\t#Carica i dati di test\n",
        "testGenerator = test_datagen.flow_from_directory(\n",
        "\ttest_dir,\n",
        "\ttarget_size=image_size,\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='categorical',\n",
        "\tshuffle=False  # Mantieni shuffle a False per i dati di test\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvHHcc_IitsL"
      },
      "source": [
        "**Making the preprocessing layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDoEwgLPhrE5"
      },
      "outputs": [],
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(224,224),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the first model**"
      ],
      "metadata": {
        "id": "YOexAJyE04cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_model = Sequential()\n",
        "first_model.add(resize_and_rescale)\n",
        "first_model.add(data_augmentation)\n",
        "first_model.add(base_model)\n",
        "first_model.add(layers.GlobalAveragePooling2D())\n",
        "first_model.add(layers.Dense(512, activation = \"relu\"))\n",
        "first_model.add(layers.Dropout(0,2))\n",
        "first_model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "first_model.build((None,) + input_shape)\n",
        "# Complitation of the model\n",
        "first_model.compile(optimizer=keras.optimizers.Adam(),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "first_model.summary()\n",
        "\n",
        "# Crea un oggetto StringIO per salvare il summary del modello come stringa\n",
        "complete_first_model_summary_string = io.StringIO()\n",
        "\n",
        "# Salva il summary del modello come stringa\n",
        "first_model.summary(print_fn=lambda x: complete_first_model_summary_string.write(x + '\\n'))\n",
        "\n",
        "# Scrivi la stringa su un file\n",
        "with open('./IntelligentSystems/stats/complete_first_model_summary.txt', 'w') as f:\n",
        "  f.write(complete_first_model_summary_string.getvalue())\n",
        "\n",
        "# Salva una rappresentazione grafica del modello come immagine\n",
        "tf.keras.utils.plot_model(first_model, to_file='./IntelligentSystems/stats/complete_first_model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "HQbmcLS90gk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ottenere le etichette reali del set di dati di test\n",
        "labels = testGenerator.classes\n",
        "# Ottieni l'elenco delle cartelle (classi) nel dataset\n",
        "class_labels = sorted(os.listdir('./dataset/food-101/test'))"
      ],
      "metadata": {
        "id": "sLHmlj0A1z7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = os.path.join(savingData_dir_name, 'food_101_pretrained_first_model.h5')\n",
        "callbacks_list = [\n",
        "    callbacks.ModelCheckpoint(\n",
        "        filepath=save_path,\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        mode='max')\n",
        "]"
      ],
      "metadata": {
        "id": "nynpNYh515yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = first_model.fit(\n",
        "  \ttrainGenerator,\n",
        "    steps_per_epoch=trainGenerator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    validation_data=valGenerator,\n",
        "    validation_steps=valGenerator.samples // batch_size)"
      ],
      "metadata": {
        "id": "Al_U-loL10yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyplot.subplot(211)\n",
        "pyplot.title('Cross Entropy Loss')\n",
        "pyplot.plot(history.history['loss'], color='blue', label='Training loss', marker='o')\n",
        "pyplot.plot(history.history['val_loss'], color='orange', label='Validation loss', marker='o', linestyle='--')\n",
        "pyplot.legend()\n",
        "\n",
        "# Margine fra i due subplot\n",
        "pyplot.subplots_adjust(left=0.2, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
        "\n",
        "# Accuracy\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Classification Accuracy')\n",
        "pyplot.plot(history.history['accuracy'], color='blue', label='Training accuracy', marker='o')\n",
        "pyplot.plot(history.history['val_accuracy'], color='orange', label='Validation accuracy', marker='o', linestyle='--')\n",
        "pyplot.legend(loc=\"upper left\")\n",
        "\n",
        "if not os.path.exists('./IntelligentSystems/graphs'):\n",
        "  os.makedirs('./IntelligentSystems/graphs')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'first_model_plot.png')\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ],
      "metadata": {
        "id": "C-8rksZl2RBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = first_model.evaluate(testGenerator)\n",
        "print('Test loss:', scores[0]*100)\n",
        "print('Test accuracy:', scores[1]*100)"
      ],
      "metadata": {
        "id": "a7OETPjD2cUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ottenere le predizioni del modello sul set di dati di test\n",
        "predictions = model.predict(testGenerator, steps = None )\n",
        "\n",
        "# Calcola la precision\n",
        "precision = precision_score(labels, predictions.argmax(axis=1), average=None)\n",
        "\n",
        "# Calcola la recall\n",
        "recall = recall_score(labels, predictions.argmax(axis=1), average=None)\n",
        "\n",
        "# Calcolo del punteggio F1\n",
        "f1Score = f1_score(labels, predictions.argmax(axis=1), average=None)"
      ],
      "metadata": {
        "id": "ob5JA7NI2lxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, (ax1, ax2, ax3) = pyplot.subplots(3, sharex=True, figsize=(20, 15))\n",
        "ax1.bar(class_labels, precision)\n",
        "ax1.set_title('Precision per classe')\n",
        "ax2.bar(class_labels, recall)\n",
        "ax2.set_title('Recall per classe')\n",
        "ax3.bar(class_labels, f1Score)\n",
        "ax3.set_title('F1 Score per classe')\n",
        "pyplot.xticks(rotation=90)\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'metricsPlotFirstModel.png')\n",
        "pyplot.show()\n",
        "pyplot.close()\n",
        "# Apertura del file in modalità scrittura\n",
        "with open('./IntelligentSystems/stats/metrics4LabelFirstModel.txt', 'w') as file:\n",
        "  # Scrittura delle etichette, precisione e recall su file\n",
        "  for label, precision, recall in zip(class_labels, precision, recall):\n",
        "    file.write(f'Label: {label}\\n')\n",
        "    file.write(f'Precision: {precision}\\n')\n",
        "    file.write(f'Recall: {recall}\\n')\n",
        "    file.write('\\n')\n",
        "  file.write(f'F1 Score: {f1Score}\\n')"
      ],
      "metadata": {
        "id": "pYVv5n6p2r1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_mat = confusion_matrix(labels, predictions.argmax(axis=1))\n",
        "pyplot.figure(figsize=(20, 10))\n",
        "# Imposta la dimensione del font per le etichette\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "# Aggiungere etichette agli assi\n",
        "pyplot.xlabel('Predicted labels')\n",
        "pyplot.ylabel('True labels')\n",
        "\n",
        "# Aggiungere un titolo al grafico\n",
        "pyplot.title('Confusion Matrix')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/stats/' + 'confusionMatrix0.png')\n",
        "# Mostrare il grafico\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ],
      "metadata": {
        "id": "bBw_7X1D24l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tuning the model**"
      ],
      "metadata": {
        "id": "-NPQyHXB-iLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = keras_tuner.Hyperband(build_model,\n",
        "                    objective='val_accuracy',\n",
        "                    max_epochs=20,\n",
        "                    factor=3,\n",
        "                    directory='/content/drive/MyDrive/IntelligentSystems',\n",
        "                    project_name='my_project')\n",
        "\n",
        "tuner.search(trainGenerator, epochs=50, validation_data=valGenerator, verbose=1 )\n",
        "\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "print(best_hps.get('learning_rate'))\n",
        "print(best_model.summary())"
      ],
      "metadata": {
        "id": "BShiZWM2-UFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfUacCv9i9W0"
      },
      "source": [
        "**Creating the tuned model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20UKL_E8h1Tu"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(resize_and_rescale)\n",
        "model.add(data_augmentation)\n",
        "model.add(base_model)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(1024, activation = \"relu\"))\n",
        "model.add(layers.Dense(1024, activation = \"relu\"))\n",
        "model.add(layers.Dropout(rate=0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "model.build((None,) + input_shape)\n",
        "# Complitation of the model\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Crea un oggetto StringIO per salvare il summary del modello come stringa\n",
        "complete_model_summary_string = io.StringIO()\n",
        "\n",
        "# Salva il summary del modello come stringa\n",
        "model.summary(print_fn=lambda x: complete_model_summary_string.write(x + '\\n'))\n",
        "\n",
        "# Scrivi la stringa su un file\n",
        "with open('./IntelligentSystems/stats/complete_model_summary.txt', 'w') as f:\n",
        "  f.write(complete_model_summary_string.getvalue())\n",
        "\n",
        "# Salva una rappresentazione grafica del modello come immagine\n",
        "tf.keras.utils.plot_model(model, to_file='./IntelligentSystems/stats/complete_model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Fx5J52B0aI4"
      },
      "outputs": [],
      "source": [
        "# Ottenere le etichette reali del set di dati di test\n",
        "labels = testGenerator.classes\n",
        "# Ottieni l'elenco delle cartelle (classi) nel dataset\n",
        "class_labels = sorted(os.listdir('./dataset/food-101/test'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSKm6Xhvj3Sn"
      },
      "source": [
        "**Defining checkpoints**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eANo6vZbj8fT"
      },
      "outputs": [],
      "source": [
        "save_path = os.path.join(savingData_dir_name, 'food_101_pretrained.h5')\n",
        "# Definisci il callback EarlyStopping\n",
        "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "callbacks_list = [\n",
        "    callbacks.ModelCheckpoint(\n",
        "        filepath=save_path,\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        mode='max'),\n",
        "    early_stopping\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDGRrhI1z7wU"
      },
      "source": [
        "**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsuDm9eWz3Nv"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "history0 = model.fit(\n",
        "  \ttrainGenerator,\n",
        "    steps_per_epoch=trainGenerator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    validation_data=valGenerator,\n",
        "    validation_steps=valGenerator.samples // batch_size)\n",
        "\n",
        "best_epochs0 = early_stopping.stopped_epoch + 1\n",
        "print(\"Best Number of Epochs:\", best_epochs0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9xg5zbC0ms5"
      },
      "source": [
        "**Plotting the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfZnDm90zrjn"
      },
      "outputs": [],
      "source": [
        "pyplot.subplot(211)\n",
        "pyplot.title('Cross Entropy Loss')\n",
        "pyplot.plot(history0.history['loss'], color='blue', label='Training loss', marker='o')\n",
        "pyplot.plot(history0.history['val_loss'], color='orange', label='Validation loss', marker='o', linestyle='--')\n",
        "pyplot.legend()\n",
        "\n",
        "# Margine fra i due subplot\n",
        "pyplot.subplots_adjust(left=0.2, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
        "\n",
        "# Accuracy\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Classification Accuracy')\n",
        "pyplot.plot(history0.history['accuracy'], color='blue', label='Training accuracy', marker='o')\n",
        "pyplot.plot(history0.history['val_accuracy'], color='orange', label='Validation accuracy', marker='o', linestyle='--')\n",
        "pyplot.legend(loc=\"upper left\")\n",
        "\n",
        "if not os.path.exists('./IntelligentSystems/graphs'):\n",
        "  os.makedirs('./IntelligentSystems/graphs')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'plot.png')\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4MzjC3TqmVx"
      },
      "source": [
        "**Evaluating the new trained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7IEEfSCqlJl"
      },
      "outputs": [],
      "source": [
        "scores0 = model.evaluate(testGenerator)\n",
        "print('Test loss:', scores0[0]*100)\n",
        "print('Test accuracy:', scores0[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRCY-TLa1tvx"
      },
      "outputs": [],
      "source": [
        "# Ottenere le predizioni del modello sul set di dati di test\n",
        "predictions = model.predict(testGenerator, steps = None )\n",
        "\n",
        "# Calcola la precision\n",
        "precision = precision_score(labels, predictions.argmax(axis=1), average=None)\n",
        "\n",
        "# Calcola la recall\n",
        "recall = recall_score(labels, predictions.argmax(axis=1), average=None)\n",
        "\n",
        "# Calcolo del punteggio F1\n",
        "f1Score = f1_score(labels, predictions.argmax(axis=1), average=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gSWSqI02s2S"
      },
      "outputs": [],
      "source": [
        "f, (ax1, ax2, ax3) = pyplot.subplots(3, sharex=True, figsize=(20, 15))\n",
        "ax1.bar(class_labels, precision)\n",
        "ax1.set_title('Precision per classe')\n",
        "ax2.bar(class_labels, recall)\n",
        "ax2.set_title('Recall per classe')\n",
        "ax3.bar(class_labels, f1Score)\n",
        "ax3.set_title('F1 Score per classe')\n",
        "pyplot.xticks(rotation=90)\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'metricsPlot0.png')\n",
        "pyplot.show()\n",
        "pyplot.close()\n",
        "# Apertura del file in modalità scrittura\n",
        "with open('./IntelligentSystems/stats/metrics4Label0.txt', 'w') as file:\n",
        "  # Scrittura delle etichette, precisione e recall su file\n",
        "  for label, precision, recall in zip(class_labels, precision, recall):\n",
        "    file.write(f'Label: {label}\\n')\n",
        "    file.write(f'Precision: {precision}\\n')\n",
        "    file.write(f'Recall: {recall}\\n')\n",
        "    file.write('\\n')\n",
        "  file.write(f'F1 Score: {f1Score}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neQYkqv59OBi"
      },
      "outputs": [],
      "source": [
        "confusion_mat = confusion_matrix(labels, predictions.argmax(axis=1))\n",
        "pyplot.figure(figsize=(20, 10))\n",
        "# Imposta la dimensione del font per le etichette\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "# Aggiungere etichette agli assi\n",
        "pyplot.xlabel('Predicted labels')\n",
        "pyplot.ylabel('True labels')\n",
        "\n",
        "# Aggiungere un titolo al grafico\n",
        "pyplot.title('Confusion Matrix')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/stats/' + 'confusionMatrix0.png')\n",
        "# Mostrare il grafico\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiZ0cB-UkCf5"
      },
      "source": [
        "**FINE TUNING - 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR3WIDddEEVq"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in base_model.layers:\n",
        "    if layer.name == 'Conv_1':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBiSqx4gwcoO"
      },
      "outputs": [],
      "source": [
        "save_path2 = os.path.join(savingData_dir_name, 'food_101_pretrained2.h5')\n",
        "\n",
        "callbacks_list = [\n",
        "    callbacks.ModelCheckpoint(\n",
        "    filepath=save_path2,\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='max'),\n",
        "    early_stopping\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jFn0KJ6kYOV"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Training the model\n",
        "history1 = model.fit(\n",
        "  \ttrainGenerator,\n",
        "    steps_per_epoch=trainGenerator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    validation_data=valGenerator,\n",
        "    validation_steps=valGenerator.samples // batch_size)\n",
        "\n",
        "best_epochs1 = early_stopping.stopped_epoch + 1\n",
        "print(\"Best Number of Epochs:\", best_epochs1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ftDd02t0vin"
      },
      "source": [
        "**Plotting the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X58bdFXLkd6s"
      },
      "outputs": [],
      "source": [
        "pyplot.subplot(211)\n",
        "pyplot.title('Cross Entropy Loss')\n",
        "pyplot.plot(history1.history['loss'], color='blue', label='Training loss', marker='o')\n",
        "pyplot.plot(history1.history['val_loss'], color='orange', label='Validation loss', marker='o', linestyle='--')\n",
        "pyplot.legend()\n",
        "\n",
        "\n",
        "# Margine fra i due subplot\n",
        "pyplot.subplots_adjust(left=0.2, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
        "\n",
        "# Accuracy\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Classification Accuracy')\n",
        "pyplot.plot(history1.history['accuracy'], color='blue', label='Training accuracy', marker='o')\n",
        "pyplot.plot(history1.history['val_accuracy'], color='orange', label='Validation accuracy', marker='o', linestyle='--')\n",
        "pyplot.legend(loc=\"upper left\")\n",
        "\n",
        "if not os.path.exists('./IntelligentSystems/graphs'):\n",
        "  os.makedirs('./IntelligentSystems/graphs')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'unfreeze1plot.png')\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaqBADahlEoa"
      },
      "outputs": [],
      "source": [
        "scores1 = model.evaluate(testGenerator)\n",
        "print('Test loss:', scores1[0]*100)\n",
        "print('Test accuracy:', scores1[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9QAA6Sy3zcK"
      },
      "outputs": [],
      "source": [
        "# Ottenere le predizioni del modello sul set di dati di test\n",
        "predictions = model.predict(testGenerator, steps = None )\n",
        "\n",
        "# Calcola la precision\n",
        "precision = precision_score(labels, predictions.argmax(axis=1), average=None)\n",
        "\n",
        "# Calcola la recall\n",
        "recall = recall_score(labels, predictions.argmax(axis=1), average=None)\n",
        "\n",
        "# Calcolo del punteggio F1\n",
        "f1Score = f1_score(labels, predictions.argmax(axis=1), average=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjhBsc_S376P"
      },
      "outputs": [],
      "source": [
        "f, (ax1, ax2, ax3) = pyplot.subplots(3, sharex=True, figsize=(20, 15))\n",
        "ax1.bar(class_labels, precision)\n",
        "ax1.set_title('Precision per classe')\n",
        "ax2.bar(class_labels, recall)\n",
        "ax2.set_title('Recall per classe')\n",
        "ax3.bar(class_labels, f1Score)\n",
        "ax3.set_title('F1 Score per classe')\n",
        "pyplot.xticks(rotation=90)\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'metricsPlot1.png')\n",
        "pyplot.show()\n",
        "pyplot.close()\n",
        "# Apertura del file in modalità scrittura\n",
        "with open('./IntelligentSystems/stats/metrics4Label1.txt', 'w') as file:\n",
        "  # Scrittura delle etichette, precisione e recall su file\n",
        "  for label, precision, recall in zip(class_labels, precision, recall):\n",
        "    file.write(f'Label: {label}\\n')\n",
        "    file.write(f'Precision: {precision}\\n')\n",
        "    file.write(f'Recall: {recall}\\n')\n",
        "    file.write('\\n')\n",
        "  file.write(f'F1 Score: {f1Score}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UFlLEfZ9LNY"
      },
      "outputs": [],
      "source": [
        "confusion_mat = confusion_matrix(labels, predictions.argmax(axis=1))\n",
        "pyplot.figure(figsize=(20, 10))\n",
        "# Imposta la dimensione del font per le etichette\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "# Aggiungere etichette agli assi\n",
        "pyplot.xlabel('Predicted labels')\n",
        "pyplot.ylabel('True labels')\n",
        "\n",
        "# Aggiungere un titolo al grafico\n",
        "pyplot.title('Confusion Matrix')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/stats/' + 'confusionMatrix1.png')\n",
        "# Mostrare il grafico\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kgBptPskODQ"
      },
      "source": [
        "**FINE TUNING - 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Xky_vWoPTBB"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in base_model.layers:\n",
        "    if layer.name == 'block_16_project':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxmvY_wfwliT"
      },
      "outputs": [],
      "source": [
        "save_path3 = os.path.join(savingData_dir_name, 'food_101_pretrained3.h5')\n",
        "\n",
        "callbacks_list = [\n",
        "    callbacks.ModelCheckpoint(\n",
        "    filepath=save_path3,\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='max'),\n",
        "    early_stopping\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dugQl46akpMl"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics=[\"accuracy\"])\n",
        "# Training the model\n",
        "history2 = model.fit(\n",
        "  \ttrainGenerator,\n",
        "    steps_per_epoch=trainGenerator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    validation_data=valGenerator,\n",
        "    validation_steps=valGenerator.samples // batch_size)\n",
        "\n",
        "best_epochs2 = early_stopping.stopped_epoch + 1\n",
        "print(\"Best Number of Epochs:\", best_epochs2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGkMoJJN0xlm"
      },
      "source": [
        "**Plotting the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrZMVWXQkq-i"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Cross Entropy Loss')\n",
        "pyplot.plot(history2.history['loss'], color='blue', label='Training loss', marker='o')\n",
        "pyplot.plot(history2.history['val_loss'], color='orange', label='Validation loss', marker='o', linestyle='--')\n",
        "pyplot.legend()\n",
        "\n",
        "\n",
        "# Margine fra i due subplot\n",
        "pyplot.subplots_adjust(left=0.2, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
        "# Accuracy\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Classification Accuracy')\n",
        "pyplot.plot(history2.history['accuracy'], color='blue', label='Training accuracy', marker='o')\n",
        "pyplot.plot(history2.history['val_accuracy'], color='orange', label='Validation accuracy', marker='o', linestyle='--')\n",
        "pyplot.legend(loc=\"upper left\")\n",
        "\n",
        "if not os.path.exists('./IntelligentSystems/graphs'):\n",
        "  os.makedirs('./IntelligentSystems/graphs')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'unfreeze2plot.png')\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GYY9o1mlH78"
      },
      "outputs": [],
      "source": [
        "scores2 = model.evaluate(testGenerator)\n",
        "print('Test loss:', scores2[0]*100)\n",
        "print('Test accuracy:', scores2[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdKzuDjA4TZr"
      },
      "outputs": [],
      "source": [
        "# Ottenere le predizioni del modello sul set di dati di test\n",
        "predictions = model.predict(testGenerator, steps = None )\n",
        "\n",
        "# Calcola la precision\n",
        "precision = precision_score(labels, predictions.argmax(axis=1), average=None)\n",
        "\n",
        "# Calcola la recall\n",
        "recall = recall_score(labels, predictions.argmax(axis=1), average=None)\n",
        "\n",
        "# Calcolo del punteggio F1\n",
        "f1Score = f1_score(labels, predictions.argmax(axis=1), average=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgv1sNvi4GB8"
      },
      "outputs": [],
      "source": [
        "f, (ax1, ax2, ax3) = pyplot.subplots(3, sharex=True, figsize=(20, 15))\n",
        "ax1.bar(class_labels, precision)\n",
        "ax1.set_title('Precision per classe')\n",
        "ax2.bar(class_labels, recall)\n",
        "ax2.set_title('Recall per classe')\n",
        "ax3.bar(class_labels, f1Score)\n",
        "ax3.set_title('F1 Score per classe')\n",
        "pyplot.xticks(rotation=90)\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'metricsPlot2.png')\n",
        "pyplot.show()\n",
        "pyplot.close()\n",
        "# Apertura del file in modalità scrittura\n",
        "with open('./IntelligentSystems/stats/metrics4Label2.txt', 'w') as file:\n",
        "  # Scrittura delle etichette, precisione e recall su file\n",
        "  for label, precision, recall in zip(class_labels, precision, recall):\n",
        "    file.write(f'Label: {label}\\n')\n",
        "    file.write(f'Precision: {precision}\\n')\n",
        "    file.write(f'Recall: {recall}\\n')\n",
        "    file.write('\\n')\n",
        "  file.write(f'F1 Score: {f1Score}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGpGvM1j9F2n"
      },
      "outputs": [],
      "source": [
        "confusion_mat = confusion_matrix(labels, predictions.argmax(axis=1))\n",
        "pyplot.figure(figsize=(20, 10))\n",
        "# Imposta la dimensione del font per le etichette\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "# Aggiungere etichette agli assi\n",
        "pyplot.xlabel('Predicted labels')\n",
        "pyplot.ylabel('True labels')\n",
        "\n",
        "# Aggiungere un titolo al grafico\n",
        "pyplot.title('Confusion Matrix')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/stats/' + 'confusionMatrix2.png')\n",
        "# Mostrare il grafico\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVjiL_2AkQs7"
      },
      "source": [
        "**FINE TUNING - 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rENO6DH9Povg"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in base_model.layers:\n",
        "    if layer.name == 'block_16_expand':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-yK_PbiwpqF"
      },
      "outputs": [],
      "source": [
        "save_path4 = os.path.join(savingData_dir_name, 'food_101_pretrained4.h5')\n",
        "\n",
        "callbacks_list = [\n",
        "    callbacks.ModelCheckpoint(\n",
        "    filepath=save_path4,\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='max'),\n",
        "    early_stopping\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9huoqETkyYz"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Training the model\n",
        "history3 = model.fit(\n",
        "  \ttrainGenerator,\n",
        "    steps_per_epoch=trainGenerator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    validation_data=valGenerator,\n",
        "    validation_steps=valGenerator.samples // batch_size)\n",
        "\n",
        "best_epochs3 = early_stopping.stopped_epoch + 1\n",
        "print(\"Best Number of Epochs:\", best_epochs3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UmPdXKU0zx6"
      },
      "source": [
        "**Plotting the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbi_s1kfkzbc"
      },
      "outputs": [],
      "source": [
        "pyplot.subplot(211)\n",
        "pyplot.title('Cross Entropy Loss')\n",
        "pyplot.plot(history3.history['loss'], color='blue', label='Training loss', marker='o')\n",
        "pyplot.plot(history3.history['val_loss'], color='orange', label='Validation loss', marker='o', linestyle='--')\n",
        "pyplot.legend()\n",
        "# Margine fra i due subplot\n",
        "pyplot.subplots_adjust(left=0.2, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
        "\n",
        "\n",
        "# Accuracy\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Classification Accuracy')\n",
        "pyplot.plot(history3.history['accuracy'], color='blue', label='Training accuracy', marker='o')\n",
        "pyplot.plot(history3.history['val_accuracy'], color='orange', label='Validation accuracy', marker='o', linestyle='--')\n",
        "pyplot.legend(loc=\"upper left\")\n",
        "\n",
        "if not os.path.exists('./IntelligentSystems/graphs'):\n",
        "  os.makedirs('./IntelligentSystems/graphs')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'unfreeze3plot.png')\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HTJHQ2SlJaC"
      },
      "outputs": [],
      "source": [
        "scores3 = model.evaluate(testGenerator)\n",
        "print('Test loss:', scores3[0]*100)\n",
        "print('Test accuracy:', scores3[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeX3kfKN4lKT"
      },
      "outputs": [],
      "source": [
        "# Ottenere le predizioni del modello sul set di dati di test\n",
        "predictions = model.predict(testGenerator, steps = None )\n",
        "\n",
        "# Calcola la precision\n",
        "precision = precision_score(labels, predictions.argmax(axis=1), average=None)\n",
        "\n",
        "# Calcola la recall\n",
        "recall = recall_score(labels, predictions.argmax(axis=1), average=None)\n",
        "\n",
        "# Calcolo del punteggio F1\n",
        "f1Score = f1_score(labels, predictions.argmax(axis=1), average=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Dooi2e4mPS"
      },
      "outputs": [],
      "source": [
        "f, (ax1, ax2, ax3) = pyplot.subplots(3, sharex=True, figsize=(20, 15))\n",
        "ax1.bar(class_labels, precision)\n",
        "ax1.set_title('Precision per classe')\n",
        "ax2.bar(class_labels, recall)\n",
        "ax2.set_title('Recall per classe')\n",
        "ax3.bar(class_labels, f1Score)\n",
        "ax3.set_title('F1 Score per classe')\n",
        "pyplot.xticks(rotation=90)\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'metricsPlot3.png')\n",
        "pyplot.show()\n",
        "pyplot.close()\n",
        "# Apertura del file in modalità scrittura\n",
        "with open('./IntelligentSystems/stats/metrics4Label3.txt', 'w') as file:\n",
        "  # Scrittura delle etichette, precisione e recall su file\n",
        "  for label, precision, recall in zip(class_labels, precision, recall):\n",
        "    file.write(f'Label: {label}\\n')\n",
        "    file.write(f'Precision: {precision}\\n')\n",
        "    file.write(f'Recall: {recall}\\n')\n",
        "    file.write('\\n')\n",
        "  file.write(f'F1 Score: {f1Score}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll6EebRa8jne"
      },
      "outputs": [],
      "source": [
        "confusion_mat = confusion_matrix(labels, predictions.argmax(axis=1))\n",
        "pyplot.figure(figsize=(20, 10))\n",
        "# Imposta la dimensione del font per le etichette\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "# Aggiungere etichette agli assi\n",
        "pyplot.xlabel('Predicted labels')\n",
        "pyplot.ylabel('True labels')\n",
        "\n",
        "# Aggiungere un titolo al grafico\n",
        "pyplot.title('Confusion Matrix')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/stats/' + 'confusionMatrix3.png')\n",
        "# Mostrare il grafico\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVsaa-ga55Zj"
      },
      "outputs": [],
      "source": [
        "pyplot.subplot(211)\n",
        "pyplot.title('Training Loss Comparison')\n",
        "pyplot.plot(history0.history['loss'], color='blue', label='Freezed', marker='o')\n",
        "pyplot.plot(history1.history['loss'], color='orange', label='Tuning-1', marker='o')\n",
        "pyplot.plot(history2.history['loss'], color='green', label='Tuning-2', marker='o')\n",
        "pyplot.plot(history3.history['loss'], color='pink', label='Tuning-3', marker='o')\n",
        "pyplot.legend()\n",
        "\n",
        "# Margine fra i due subplot\n",
        "pyplot.subplots_adjust(left=0.2, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
        "\n",
        "# Accuracy\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Training Accuracy Comparison')\n",
        "pyplot.plot(history0.history['accuracy'], color='blue', label='Freezed', marker='o')\n",
        "pyplot.plot(history1.history['accuracy'], color='orange', label='Tuning-1', marker='o')\n",
        "pyplot.plot(history2.history['accuracy'], color='green', label='Tuning-2', marker='o')\n",
        "pyplot.plot(history3.history['accuracy'], color='pink', label='Tuning-3', marker='o')\n",
        "pyplot.legend()\n",
        "\n",
        "if not os.path.exists('./IntelligentSystems/graphs'):\n",
        "  os.makedirs('./IntelligentSystems/graphs')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'trainingComparison.png')\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUvazzer7Q4c"
      },
      "outputs": [],
      "source": [
        "pyplot.subplot(211)\n",
        "pyplot.title('Validation Loss Comparison')\n",
        "pyplot.plot(history0.history['val_loss'], color='blue', label='Freezed', marker='o')\n",
        "pyplot.plot(history1.history['val_loss'], color='orange', label='Tuning-1', marker='o')\n",
        "pyplot.plot(history2.history['val_loss'], color='green', label='Tuning-2', marker='o')\n",
        "pyplot.plot(history3.history['val_loss'], color='pink', label='Tuning-3', marker='o')\n",
        "pyplot.legend()\n",
        "\n",
        "# Margine fra i due subplot\n",
        "pyplot.subplots_adjust(left=0.2, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
        "\n",
        "# Accuracy\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Validation Accuracy Comparison')\n",
        "pyplot.plot(history0.history['val_accuracy'], color='blue', label='Freezed', marker='o')\n",
        "pyplot.plot(history1.history['val_accuracy'], color='orange', label='Tuning-1', marker='o')\n",
        "pyplot.plot(history2.history['val_accuracy'], color='green', label='Tuning-2', marker='o')\n",
        "pyplot.plot(history3.history['val_accuracy'], color='pink', label='Tuning-3', marker='o')\n",
        "pyplot.legend()\n",
        "\n",
        "if not os.path.exists('./IntelligentSystems/graphs'):\n",
        "  os.makedirs('./IntelligentSystems/graphs')\n",
        "\n",
        "# Salva il grafico\n",
        "pyplot.savefig('./IntelligentSystems/graphs/' + 'validationComparison.png')\n",
        "pyplot.show()\n",
        "pyplot.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}